{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize as WordTokenizer\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set the path of all files\n",
    "spam_test_files = r'data\\spam-test\\*.txt'\n",
    "not_spam_test_files=r'data\\nonspam-test\\*.txt'\n",
    "\n",
    "# method to get files data from disk\n",
    "def get_DatafromFiles(file_path):\n",
    "    filesList = []\n",
    "    file_data_list=[]\n",
    "    for files in glob.glob(file_path):\n",
    "        filesList.append(files) \n",
    "    for file in filesList:\n",
    "        with open(file,'r') as curfile:\n",
    "            file_data_list.append(curfile.readline())\n",
    "    return file_data_list\n",
    "spam_test_df=pd.DataFrame(get_DatafromFiles(spam_test_files),columns=['email'])\n",
    "spam_test_df['actual_label']='spam'\n",
    "not_spam_test_df=pd.DataFrame(get_DatafromFiles(not_spam_test_files),columns=['email'])\n",
    "not_spam_test_df['actual_label']='not-spam'\n",
    "\n",
    "test_df=not_spam_test_df.append(spam_test_df)\n",
    "test_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#method to genrate tokens\n",
    "def word_tokenizer(data):\n",
    "    return str(nltk.word_tokenize(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the tokens for prediction\n",
    "test_df_tokenized =test_df['email'].apply(lambda x:word_tokenizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the vectors from saved file\n",
    "TfidfVectorizer_pickle_file=r'models\\TfidfVectorizer_pickle.dat'\n",
    "TfidfVectorizer_pickle = open(TfidfVectorizer_pickle_file, 'rb')\n",
    "tfidf_vectorizer =pickle.load(TfidfVectorizer_pickle)\n",
    "\n",
    "#transform the data\n",
    "test_df_vec=tfidf_vectorizer.transform(test_df_tokenized)\n",
    "TfidfVectorizer_pickle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the saved classifer model for prediction\n",
    "Classifier_pickle_file=r'models\\Classifier_pickle.dat'\n",
    "Classifier_pickle = open(Classifier_pickle_file, 'rb')\n",
    "Classifier=pickle.load(Classifier_pickle)\n",
    "Classifier_pickle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the prediction result and confidence score\n",
    "predict_test=pd.DataFrame(Classifier.predict(test_df_vec),columns=['predicted_label'])\n",
    "predict_proba_test=pd.DataFrame(Classifier.predict_proba(test_df_vec))\n",
    "predict_proba_test=pd.DataFrame(round(predict_proba_test.max(axis=1)*100).astype(int),columns=['confidence_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#combine all data frames for final result\n",
    "result1 = test_df.join(predict_test)\n",
    "final_result=result1.join(predict_proba_test)\n",
    "final_result['confidence_score']=final_result['confidence_score'].astype(str)+' %'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save the result into file\n",
    "final_result.to_csv('result\\predicted_result.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
